
<!-- TOC -->

- [GPT-2生成式多轮对话](#gpt-2生成式多轮对话)
    - [框架](#框架)
- [CDial-GPT](#cdial-gpt)
    - [模型选择](#模型选择)
    - [数据处理](#数据处理)
    - [训练过程](#训练过程)
- [GPT2-chitchat](#gpt2-chitchat)
    - [模型选择](#模型选择-1)
    - [数据预处理](#数据预处理)
    - [训练思路](#训练思路)
    - [交互思路](#交互思路)
    - [源码难点](#源码难点)

<!-- /TOC -->

## GPT-2生成式多轮对话

### 框架

<img src="https://img-blog.csdnimg.cn/2020021620210095.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2c1MzQ0NDE5MjE=,size_16,color_FFFFFF,t_70">

* **无监督语料库学习 | 左侧**

    * 目标：标准语言模型，前文状态下最大化当前词的概率

    * 公式：多注意力机制 + 多层transfomer

        <img src="https://img-blog.csdnimg.cn/20200216200304928.png" style="zoom:67%;" >

        * 对词的上文向量进行多头自注意力机制

        > U：词的上文向量（该词的前k个词）
        >
        > $W_e$：词嵌入矩阵，embedding
        >
        > $W_p$：词位置矩阵

* **Fine tuning：监督学习 | 右侧**

    * 将预训练模型的最终输出，作为输入传入线性输出层j计算$h^m_lW^y$

    * 问答系统的预处理：在一个文档环境z、一个问题q和一组可能答案{ak}之间加分隔符$

        输入为[z; q; $; ak]，模型计算每个ak的possibility => softmax

## CDial-GPT

**【编码方式】**

<img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201123090949440.png" alt="image-20201123090949440" style="zoom:67%;" />

### 模型选择

* 需要根据历史序列信息，预测出问题的答案 => 单向即可

* 一些输入，一个输出 => Seq2seq/GPT

* GPT

    <img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201123075527988.png" alt="image-20201123075527988" style="zoom:67%;" />

    <img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X2pwZy81ZmtuYjQxaWI5cUVaVXpTQTJ4czhLaFpGZ2hSSTlvUUVNbHZLazF5eGM3dGUwaEFkUlJ4aWI1RkhFVm84M0pNRzNkVVNEMGdCZnhpY1QwaHR1b2ljV3RLUlEvNjQw?x-oss-process=image/format,png" style="zoom: 50%;" >
    
    > 分隔符SEP表示句子的结束：前后的句子拥有不同的segment id。

### 数据处理

* 将所有历史对话拼接成单句文本，用[SEP]分隔，作为模型输入

* 相对位置编码：GPT的绝对位置编码有上限，而对话轮数可能是无限的，因此使用相对位置编码。使用NEZHA的预训练权重作为模型的初始化权重。

### 训练过程

* 预训练：基于中文小说中数据，训练12层GPT，5亿个词

    > config中的attn_pdrop：定义了attention层dropout的概率
    >
    > attention之后残差，才到全连接MLP

* 优化器：AdamW + Noam学习率衰减

* 学习率预热：1 epoch，不高于6.25e-5

* 模型

    * 12层GPT/GPT2 + 12head

    * word embedding size：768

    * position embedding：513

    * batch size：8

    * gradient accumulation：64 

        > 每加载64个batch，更新梯度并清零

* 在已得到的模型上，用STC数据集微调
    * $GPT_{novel}$：30 epochs
    * 其余模型：10 epochs，same batch size和accumulation，其余超参数不变
    * 学习率：从6.25e-5衰减到0
    * decoding strategy：top-p + temperature=0.7

## GPT2-chitchat

### 模型选择

* tokenizer：Bert，预训练模型：GPT-2
* 编码器：只编码input_id，没有mask和token type
* 损失函数
    * 用第i个token的prediction_score用来预测第i+1个token
    * 标签漂移：实际输出取[0:n-2]，labels取[1:n-1]，求交叉熵
    * 交叉熵: torch.nn.CrossEntropyLoss
        * weight：对矩阵中每个元素的损失赋予一定权重，此处为attention score

### 数据预处理

* 根据vocab创建tokenizer

* 拼接每段对话中的句子，转为id

    * 以[CLS]开头
    * [SEP]分隔各个句子
    * 存储方式：每行对应一段对话，id之间以空格分开，最后一行没有换行符
    * 注意：MMI进行token的时候，需要将对话里的句子逆序

    ```python
    # vocab_file用于找token id
    tokenizer = BertTokenizer(vocab_file)
    # MMI需要逆序处理
    if MMI:
        dialog = reverse(dialog)
        
    # 以[CLS]开头
    dialog_ids = [tokenizer.cls_token_id]
    for sent in dialog:
        dialog_ids.append(tokenizer.encode(sent, add_special_tokens=False))
        diglog_ids.append(tokenizer.sep_token_id)
    
    # 超过ctx长度的截断，以一段dialog处理为一个输入
    dialog_ids = dialog_ids[:n_ctx]
    ```

### 训练思路

1. **加载参数、设置随机种子**

    > 对话模型和MMI模型的输出目录

2. **设置GPU**

    ```python
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    ```

3. **设定日志**

4. **初始化tokenizer：BERT**

    ```python
    tokenizer = BertTokenizer(vocab_file=vocab_path)
    vocab_size = len(tokenizer)
    ```

5. **加载GPT2模型**

    ```python
    # path指明预训练模型的路径
    model = GPT2LMHeadModel.from_pretrained(path)
    # 根据训练样本的词表大小，更改模型的词表大小
    model.resize_token_embeddings(vocab_size)
    # 获取输入的最大长度
    model.config().to_dict().get('n_ctx')
    ```

6. 根据所训练的模型进行**数据预处理**

    > MMI模型和对话模型的数据处理方式有差异

7. 多GPU，默认false

8. **加载数据**

    * 从tokenized文件中加载数据

    * 划分训练集和验证集：random_split 或 train_test_split

        ```
        train_list, test_list = train_test_split(data_list, test_size=0.2, random_state=1)
        ```

9. **开始训练**

10. **测试数据**

### 交互思路

1. **利用对话模型得到candidate_response**

    * 处理当前句子与历史对话的token2id和拼接

        > 无需padding，同样长；
        >
        > 转GPU

    * 生成candidate_response (batch_size个)
        * 按batch对每个token进行预测
        
        ```mermaid
        graph TD
        A[s] --> B[ld]
        ```
        
        

2. **用MMI模型得到最佳回答**

    * 按照MMI的输入，逆序拼接candidate_response和历史对话
    * 传入MMI模型，计算loss
    * 将loss最小的回答作为

### 源码难点

> ref: https://blog.csdn.net/g534441921/article/details/104312983

* contiguous：改变张量在底层存储位置的布局

    * [ref1：contiguous](https://blog.csdn.net/gdymind/article/details/82662502?utm_source=distribute.pc_relevant.none-task)
    * [ref2：view](https://blog.csdn.net/appleml/article/details/80143212)

    > stride：内存中与相邻行第一个索引的距离，与相邻列第一个索引的距离
    >
    > <img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201124154017123.png" alt="image-20201124154017123" style="zoom:50%;" />

