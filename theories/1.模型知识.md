## Overview

<img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201127101636878.png" alt="image-20201127101636878" style="zoom: 67%;" />

<!-- TOC -->

- [Overview](#overview)
- [自编码器](#自编码器)
- [RNN](#rnn)
    - [双向RNN](#双向rnn)
    - [Seq2Seq | 多输入多输出且不等长的RNN](#seq2seq--多输入多输出且不等长的rnn)
    - [Attention机制](#attention机制)
    - [Self-Attention](#self-attention)
    - [Multi-Head Attention](#multi-head-attention)
    - [Transformer](#transformer)
        - [【Encoder结构】](#encoder结构)
        - [【Decoder的结构】](#decoder的结构)
        - [【完整结构】](#完整结构)
        - [【位置编码】](#位置编码)
    - [RNN变种结构：LSTM | 长短期记忆网络](#rnn变种结构lstm--长短期记忆网络)
    - [RNN变种结构：GRU| 门控循环单元](#rnn变种结构gru-门控循环单元)
- [Zero-shot Learning](#zero-shot-learning)
- [GPT-2](#gpt-2)
    - [模型介绍](#模型介绍)
    - [结构](#结构)
        - [【Masked Self-Attention】](#masked-self-attention)
        - [【Decoder】](#decoder)
        - [【FFNN】](#ffnn)
        - [【完整结构】](#完整结构-1)
    - [训练方式](#训练方式)
    - [Input Encoding](#input-encoding)
    - [Output&迭代步骤](#output迭代步骤)
- [DialoGPT](#dialogpt)
    - [简介](#简介)
    - [模型结构](#模型结构)
    - [互信息最大化 | MMI](#互信息最大化--mmi)
- [MASK](#mask)
    - [【填充后的各项计算】](#填充后的各项计算)
    - [乱序语言模型 | XLNet](#乱序语言模型--xlnet)
- [UNILM](#unilm)
- [Decoding Strategy](#decoding-strategy)
    - [Greedy Search](#greedy-search)
        - [Greedy Search](#greedy-search-1)
        - [Beam Search](#beam-search)
    - [Sampling](#sampling)
        - [随机Sampling](#随机sampling)
        - [Temperature Sampling](#temperature-sampling)
        - [Top-k Sampling | K表示个数](#top-k-sampling--k表示个数)
        - [Neucleus Sampling | 核采样](#neucleus-sampling--核采样)
        - [惩罚重复](#惩罚重复)
- [Bert两大任务](#bert两大任务)
    - [MLM | Masked Language Model](#mlm--masked-language-model)
    - [NSP | Next-Sentence Prediction](#nsp--next-sentence-prediction)
- [Subword算法](#subword算法)
    - [BPE | Byte-Pair Encoding](#bpe--byte-pair-encoding)
    - [WordPeice](#wordpeice)
    - [Unigram Language Model](#unigram-language-model)

<!-- /TOC -->

## 自编码器

* 输入等于输出的神经网络模型

    <img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201121160911868.png" alt="image-20201121160911868" width="50%" height="50%"/>

* 用途

    * 降维：取出输入到隐藏层的权重，对输入计算的到隐藏层
    * 降噪：加噪的数据集为输入，原数据集为输出，训练出去噪的功能

* 常见自编码器

    * 自编码器：全连接，一个隐藏层

    * 多个全连接的自编码器：多隐藏层

    * 卷积自编码器：全连接损失二维信号的空间信息，用卷积保留二维信号的空间信息

        <img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201121161217722.png" alt="image-20201121161217722" width="50%" height="50%"/>

    * 稀疏自编码器：在普通自编码器的隐藏层增加L1正则项，编码器表征的特征更稀疏（减少encoder的权重），是隐藏层的特征少

    * 降噪自编码器：以加噪数据集为输入，原数据集为输出

## RNN

**【原理】**

* forward：考虑前一个输入的隐藏状态

    * $h(t) = \sigma(Ux(t)+Wh(t−1)+b)$

    * $o(t) = Vh(t) + c$

    * 注意：RNN权值共享，共用一套$(U, W, V, b, c)$

        > 共享权值是为了降低模型的复杂度

* backward：梯度下降

**【RNN结构】**

<img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201121220002634.png" alt="image-20201121220002634" width="50%" height="50%"/>

**【优势】**

* 考虑序列化数据（“我爱你”）。通过隐藏层编码上一个神经元信息，具备记忆能力

### 双向RNN

**【原理和架构】**

* 计算公式

    * 正向（历史到当前）$h_t = f(Ux_t+Vh_{t-1}+b)$
    * 反向（未来到当前）$h'_t = f(U'x_t+V'h_{t+1}+b')$
    * 输出 $o_t = g(Vh_t + V'h'_t + c)

* 共享权重：正向共享$(U, W, V, b)$， 反向共享$(U', W', V', b')$，以及$c$

* 时间步t的输出不仅取决于此前时刻，也取决于未来时刻

    <img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201121220455230.png" alt="image-20201121220455230" width="50%" height="50%"/>

**【常见RNN结构】**

* 单输入多输出

    <img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201121161836861.png" alt="image-20201121161836861" style="zoom: 67%;" />

* 多输入多输出：输入输出等长

    <img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201121161903961.png" alt="image-20201121161903961" width="50%" height="50%"/>

* 多输入多输出：输入输出不等长 | seq2seq

### Seq2Seq | 多输入多输出且不等长的RNN

**【原理】**

* RNN + 自编码器

* Dncoder一个RNN，Decoder一个RNN？

    <img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201122101023147.png" alt="image-20201122101023147" width="50%" height="50%"/>

**【应用】**

* 机器翻译。输入与输出的意义相同，语言不同，所以不等长

**【两种主要形式】**

* 将Encoder当做一个输入，对此后每个神经元都有影响

    <img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201121162123149.png" alt="image-20201121162123149" width="50%" height="50%"/>

* 直接传给decoder整条链中的最开始结点，即要翻译的这句话之前的隐藏层状态。

    <img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201121162339083.png" alt="image-20201121162339083" width="50%" height="50%"/>

**【缺陷】**

* Decoder的输入一直是同一个输出，即都是将原本句子整个做decoder，再作为decoder的输入。

### Attention机制

* 对Seq2seq的改进：seq2seq只用一个向量表示整个句子，可能会使得源句最早的一些信息丢失

* 理解Attentition

    * 在机器翻译中，用于表示对源句某些单词的特别关注（因为正在翻译这个词）

    * 广义上，给一个query和一组values，query决模型对values的关注程度

        > query attends to the values；
        >
        > 在seq2seq中，query是当前decoder的隐藏状态，values是encoder的所有隐藏状态

**【训练步骤】**

* step1. 信息输入

* step2. 计算注意力分布的权值，每个单词有一个attention score 

    <img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201122101300371.png" alt="image-20201122101300371" width="50%" height="50%"/>

    > * 句子中每一个hidden state与encoder的hidden state点乘得到attention score（标量），实则是在比较两者的相似度，相似度高的权重高
    >
    > * 每一个decoder会得到一个权值分布c；所以共有输出序列时间步$t_2$个权值分布

* step3. 计算注意力输出，根据注意力分布权值计算输入信息的加权和

    > 即$\sum_j^{t_1}h_ja_j$=每个隐藏状态乘自己在注意力权值分布（softmax）中的占比，求和

* step4. 计算decoder的输出，直接连接注意力输出和decoder的hidden state

    <img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201122102031877.png" alt="image-20201122102031877" width="50%" height="50%"/>

    > <img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201122102351476.png" alt="image-20201122102351476" width="50%" height="50%"/>

**【原理】**

* 对Decoder中的神经元赋予不同的输入（中间语义），指明需要加重该序列的哪个部分

    <img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201121210310916.png" alt="image-20201121210310916" style="zoom: 80%;" />

* **中间语义c的计算**：权重W和编码器的隐藏层输出h加权而得

    * 有一个显示注意力的矩阵（权值w表征），对句子中每个词有自己对应的一行

    <img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201121163232596.png" alt="image-20201121163232596" width="50%" height="50%"/>

* **权值w表征**

    * hi表示当前的神经元，hj表示序列中所有的神经元（包括自己）
    * 当该分类模型可以使神经元与自己最相似时，则用于注意力机制的权值W表征训练好了（动态训练）

    <img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201121163509350.png" alt="image-20201121163509350" width="50%" height="50%"/>

**【优点】**

* 增加模型的可解释性

    <img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201122102507597.png" alt="image-20201122102507597" width="50%" height="50%"/>

### Self-Attention

**【作用】**

* 关注当前序列对当前词的影响，一般可解决指代问题(it)或有助于机器学习时态
* 目的：增强模型对当前序列的表征能力

**【公式】**

* Q(query)  =>  Attention中的decoder hidden state
* K(key) => 类似于encoder hidden state
* V(value) => 类似于encoder hidden state


<img src="https://www.zhihu.com/equation?tex=%5Ctext%7BAttention%7D%28Q%2CK%2CV%29%3D%5Ctext%7Bsoftmax%7D%28%5Cfrac%7BQK%5ET%7D%7B%5Csqrt%7Bd_k%7D%7D%29V+%5Ctag1" alt="image-20201122102507597" style="zoom: 80%;" />

**【结构】**

1. 输入：word embedding，512维，$d_{model}=512$

2. 转换拆分：将输入分别与三个权值矩阵$W^Q$, $W^K$和$W^V$相乘（均为512x64)，得到三个矩阵Q，K，V（64维，一个词对应一行）

<img src="https://pic3.zhimg.com/80/v2-bcd0d108a5b52a991d5d5b5b74d365c6_720w.jpg" style="zoom: 67%;" />

3. 计算attention score：q和k点乘，每个q都要乘整个k矩阵

> * 实质是在计算query对应了哪些key，提高这些key的权重
> * eg：query为年轻女士冬季穿的红色薄款羽绒服，搜索引擎需要根据Query匹配Key（例如商品的种类，颜色，描述等），实质也是在找相关的key，不相关的就不出现（在返回结果中的权重低）
> * 在序列中，也许是在计算当前词q与某些主题K的相似度或语义相关性（指代关系等）。query是当前单词的表示；key是所有单词的标签；value是实际的词的单词表示

4. 归一化并softmax

* 归一化：保持梯度稳定，normalization。除以K的维度

5. 计算attention output

* 对每个V加权求和，得到当前词的输出结果z
* 每个z：综合了当前的词对其他所有value的注意力情况
* 所以一个序列信息，能够得到一个Z矩阵，一行对应该序列中一个词的注意力情况

<img src="https://pic1.zhimg.com/80/v2-79b6b3c14439219777144668a008355c_720w.jpg" style="zoom: 67%;" />

### Multi-Head Attention

* 集成多个不同的self-attention

**【步骤】**

1. 将输入X分别放入n个self-attenttion，共n套$(W^Q, W^K, W^V)$。计算得到n个加权后的特征矩阵$Z_i$

    > 每个矩阵表示该序列基于不同head的注意力情况;
    >
    > 或者，每个单词对应一套自己的$(W^Q, W^K, W^V)$

2. 将$Z_i$拼接成一个大矩阵$Z$ (dim=1)

3. 经过一层全连接得到输出Z

    ​    <img src="https://pic3.zhimg.com/80/v2-c2a91ac08b34e73c7f4b415ce823840e_720w.jpg" width="50%" height="50%">

### Transformer

**【本质】| 编码器**

* Google基于并行的思想提出
* Encoders和Decoders
* 将Encoder的输出作为Decoder的输入

<img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201122221227881.png" alt="image-20201122221227881" width="50%" height="50%"/>

<img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201122222211580.png" alt="image-20201122222211580" width="50%" height="50%"/>

#### 【Encoder结构】

* **输入**：word embedding，512维，$d_{model}=512$

* **self-attention | multi-head attention**

    <img src="https://www.zhihu.com/equation?tex=%5Ctext%7BAttention%7D%28Q%2CK%2CV%29%3D%5Ctext%7Bsoftmax%7D%28%5Cfrac%7BQK%5ET%7D%7B%5Csqrt%7Bd_k%7D%7D%29V+%5Ctag1" alt="image-20201122102507597" style="zoom: 80%;" />

* 使用**残差网络的short-cut**，解决深度学习的退化问题

    <img src="https://pic1.zhimg.com/80/v2-2f06746893477aec8af0c9c3ca1c6c14_720w.jpg" width="50%" height="50%">

* **FFNW**(每个词各自)：Affine - Relu - Affine

> 从第二个encoder起，每一个的输入为前一个的输出

<img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201122222519003.png" alt="image-20201122222519003" width="50%" height="50%"/>

#### 【Decoder的结构】

<img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201122224836632.png" alt="image-20201122224836632" width="50%" height="50%"/>

* **Encoder-Decoder Attention**

    * 不同于self-attention的Q,K,V（只来自word embedding）
    * 输入：Q来自于decoder的上一个输出，K和V来自于encoder的输出矩阵
    * 计算方式：与self-attention相同

    > 当解码第 k 个特征向量时，我们只能看到第 k-1及其之前的解码结果，论文中把这种情况下的multi-head attention叫做masked multi-head attention

    <img src="https://pic1.zhimg.com/80/v2-79b6b3c14439219777144668a008355c_720w.jpg" width="50%" height="50%">

#### 【完整结构】

<img src="https://pic1.zhimg.com/80/v2-9fb280eb2a69baf5ceafcfa3581aa580_720w.jpg">

#### 【位置编码】

* **提出**

    * self-attention和feed forward都是并行的
    * 且self-attention的Q，K，V都来源于自己的embedding（只考虑了前后有哪些词，并未考虑这些词的序列）=> 无论顺序如何，都会得到类似的结果

* **如何编码位置信息**

    * 参数式编码：根据数据学习，把位置编码向量作为参数参与训练
    * 函数式编码：自己设计编码规则

* **编码规则**

    * 维度与word embedding同，维度$d_{model} = 512$

    * 便于位置编码和词嵌入直接相加，得到模型的输入

        <img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201122230519866.png" alt="image-20201122230519866"  />

        

* **编码公式**

    <img src="https://www.zhihu.com/equation?tex=PE%28pos%2C+2i%29+%3D+sin%28%5Cfrac%7Bpos%7D%7B10000%5E%7B%5Cfrac%7B2i%7D%7Bd_%7Bmodel%7D%7D%7D%7D%29+%5Ctag3" width="50%" height="50%">

    <img src="https://www.zhihu.com/equation?tex=PE%28pos%2C+2i%2B1%29+%3D+cos%28%5Cfrac%7Bpos%7D%7B10000%5E%7B%5Cfrac%7B2i%7D%7Bd_%7Bmodel%7D%7D%7D%7D%29+%5Ctag4" width="50%" height="50%">

    > <img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201122230912626.png" alt="image-20201122230912626" width="50%" height="50%"/>

* **NEZHA | 相对位置编码**

    * **已有模型**

        * Transformer的位置编码采用绝对位置编码，一共512个词
        * Bert参数式编码：**很多数据的真实数据长度达不到最大长度，因此靠后位置的位置向量训练的次数要比靠前位置的位置向量的次数少，造成靠后的参数位置编码学习的不够。**

    * **相对位置编码的意义**

        * 在计算当前位置的向量的时候，考虑与它相互依赖的token之间相对位置关系，可以更好地学习到信息之间的交互传递

    * **实现**

        * 原本的编码方式

            > $\alpha$表示注意力分数，$x_i$和$x_j$可看做第i个词和第j个词的embedding，计算两者相似度并softmax，得到$\alpha$

            <img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201123083658059.png" alt="image-20201123083658059" width="50%" height="50%"/>

        * 加入相对位置编码

            <img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201123083959833.png" alt="image-20201123083959833" style="zoom: 67%;" />

### RNN变种结构：LSTM | 长短期记忆网络

* LSTM：Long-Short Term Memory

**【RNN的结构缺陷】**

* RNN的重要特性：共享1组（U, W,b） => 同一个W连乘，梯度爆炸或梯度消失

**【LSTM结构】**

* 外部结构不变：每个神经元的计算依旧基于上一级隐藏层的输出和输入来计算

    > 因此，RNN的各种结构都能用LSTM替换（替换内部计算方式）

* 内部结构：输入门i、遗忘门f、输出门o和内部记忆单元c

    > LSTM所有神经元的四部分共享参数，即一共只有四套(U, W, b)

    * **遗忘门：$(U_f, W_f, b_f)$**

        <img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201121164557119.png" alt="image-20201121164557119" width="50%" height="50%"/>

    * **输入门：**$(U_i, W_i, b_i)$

        <img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201121164718422.png" alt="image-20201121164718422" width="50%" height="50%"/>

    * **内部记忆单元：**$(U_c, W_c, b_c)$

        * tanh：对输入x和上一层隐藏层输出计算Affine => $(U_c, W_c)$，看作有b
        * `x`：相乘，以遗忘门和输入门的输出为系数

        ![image-20201121170304370](https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201121170304370.png)

    * **输出门：**$(U_o, W_o, b_o)$
        * $o_t$：等同于RNN原本的内部计算
        * $h_t$：隐藏层输出，需要考虑输出门和内部记忆单元

    ​	<img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201121170716740.png" alt="image-20201121170716740" width="50%" height="50%"/>

**【公式参数解释】**

<img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201121170953675.png" alt="image-20201121170953675" width="50%" height="50%"/>

**【小结】**

* 当输入序列不存在有用信息，遗忘门f接近1，输入门i接近0，则$c_t=f_tc_{t-1}+i_tc'_t = c_{t-1}$。说明内部记忆单元没有更新记忆，仍保持$c_{t-1}$
* 当输入序列存在重要信息，遗忘门f接近0，输入门i接近1，则$c_t=f_tc_{t-1}+i_tc'_t = c'_t$。说明LSTM遗忘以前的记忆，仅记录当前重要记忆

### RNN变种结构：GRU| 门控循环单元

* GRU：Gated Recurrent Unit

**【GRU原理】**

* 提出：LSTM门控网络过于复杂和冗余

* GRU将遗忘门和输入门合并成更新门，将内部记忆单元和隐藏层合并成重置门

* GRU不会控制和保留内部记忆，没有输出门

    <img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201121212144059.png" alt="image-20201121212144059" width="50%" height="50%"/>

**【GRU结构】**

* **更新门$z_t$**：决定前一个时间步和当前时间步的信息有多少需要继续传递，有助于GRU记忆长期信息

    <img src="https://image.jiqizhixin.com/uploads/wangeditor/dd4f1aca-a5b6-4768-a67d-6035978a2a02/876154.png" alt="image-20201121212144059" width="50%" height="50%"/>

    * $z_t$：表示前一个时间步最终记忆$h_{t-1}$的在当前时间步最终记忆的占比
    * $1-z_t$：表示当前时间步记忆内容$h'_t$在当前时间步最终记忆的占比

    > $x_t$：第t个时间步的输入，即输入序列的第t个分量
    >
    > $\sigma$：表示sigmoid函数，将结果压缩到0与1之间

    <img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201121212445682.png" alt="image-20201121212445682" width="50%" height="50%"/>

* **重置门$r_t$：决定多少过去的信息被遗忘**

    <img src="https://image.jiqizhixin.com/uploads/wangeditor/dd4f1aca-a5b6-4768-a67d-6035978a2a02/426936.png" alt="image-20201121212144059" width="50%" height="50%"/>

    > * 当重置门接近于0，先前隐藏状态被忽略，仅用当前输入进行复位，将来也不会接收到此前的不相关信息
    >
    > * 结果也是0到1之间，起到门的作用

    <img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201121212741434.png" alt="image-20201121212741434" style="zoom: 80%;" />

* **当前时间步的记忆内容 | 由重置门控制**

    <img src="https://image.jiqizhixin.com/uploads/wangeditor/dd4f1aca-a5b6-4768-a67d-6035978a2a02/934258.png" alt="image-20201121212144059" width="50%" height="50%"/>

    * 重置门的结果在0到1之间，由此控制了此前记忆向量$h_{t-1}$的信息传输
    * 0代表该元素完全遗忘，1代表信息完全传输
    * Hadamard乘积确定要保留和遗忘的以前信息

    > ⊙：同或运算，当两者真值相同时输出真。
    >
    > ⊙：Hadamard乘积，即$ r_t$和$Uh_{t-1}$的element-wise乘积

    <img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201121213528712.png" alt="image-20201121213528712" width="50%" height="50%"/>

* **当前时间步的最终记忆**

    <img src="https://image.jiqizhixin.com/uploads/wangeditor/dd4f1aca-a5b6-4768-a67d-6035978a2a02/6678810.png" alt="image-20201121212144059" width="50%" height="50%"/>

    * 通过更新门，决定从当前记忆内容和前一时间步记忆内容中收集信息的程度

        <img src="https://image.jiqizhixin.com/uploads/wangeditor/dd4f1aca-a5b6-4768-a67d-6035978a2a02/9030611.png" alt="image-20201121213528712" style="zoom: 67%;" />

## Zero-shot Learning

* **Intro**

<img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201122233041192.png" alt="image-20201122233041192" width="50%" height="50%"/>

* **Target**

    模型对没见过的类别也能进行分类

* **基本结构**

    <img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201122233232348.png" alt="image-20201122233232348" width="50%" height="50%"/>

* **Main Idea**

    **利用训练集数据训练模型，使得模型能够对测试集的对象进行分类，但是训练集类别和测试集类别之间没有交集；期间需要借助类别的描述，来建立训练集和测试集之间的联系，从而使得模型有效**。

## GPT-2

### 模型介绍

* 模型

    * 语言模型

    * 只保留了Transformer的decoders

        <img src="https://img-blog.csdnimg.cn/20200224205617337.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2c1MzQ0NDE5MjE=,size_16,color_FFFFFF,t_70">

* 数据集：40GB数据集WebText

* 参数

    * 最小变体：需要500MB存储所有参数，保留12层decoder，维度为768
    * 最大变体：超过6.5G存储空间，使用48层decoder，维度高达1600

* 输出

    * 输出序列是逐个逐个词输出的

    * 自回归：GPT一次输出一个词，再将该输出添加到输入序列中，将新序列传入下一步作为输入

        > BERT：不是自回归，利用单词上下文（双向）计算出结果
        >
        > XLNet：自回归 + 结合上下文的方法

### 结构

#### 【Masked Self-Attention】

**【Difference】**

* self-attention考虑整个序列，注意力的最大值可能在当前词之后的某个词出现

* masked self-attention只考虑当前词及其之前的词，即注意力最大值只能在此前出现

    > 原始Transformer只能处理512个token，现在借助masked self-attention可以处理1024个token

    <img src="https://img-blog.csdnimg.cn/20200224212347105.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2c1MzQ0NDE5MjE=,size_16,color_FFFFFF,t_70" style="zoom: 40%;" >

* Masked Self-Attention：考虑了token的上文表示

**【计算方式】**

* 正常计算出当前词对所有词的注意力分数，不必softmax

* 遮蔽上三角部分

    <img src="https://img-blog.csdnimg.cn/20200226121036460.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2c1MzQ0NDE5MjE=,size_16,color_FFFFFF,t_70" width="50%" height="50%">

* 对当前有效值重新计算softmax

    <img src="https://img-blog.csdnimg.cn/2020022614005495.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2c1MzQ0NDE5MjE=,size_16,color_FFFFFF,t_70" width="50%" height="50%">

**【步骤】**

1. **Cretae q, k, v**

    > 实现时，将三个矩阵串联

    <img src="https://img-blog.csdnimg.cn/20200226142332751.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2c1MzQ0NDE5MjE=,size_16,color_FFFFFF,t_70" style="zoom: 40%;" >

2. **Split Attention heads**

    * 得到的q向量是多个head中q的串联，需要重塑

        > GPT-2中共12个head

        <img src="https://img-blog.csdnimg.cn/20200226142740224.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2c1MzQ0NDE5MjE=,size_16,color_FFFFFF,t_70" width="50%" height="50%">

3. **Attention Score**

    * 在此前的步骤中，保留此前每个词各个头的k和v

    * 对每一个head：当前词的query 点乘 此前词的key

        <img src="https://img-blog.csdnimg.cn/20200226143409640.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2c1MzQ0NDE5MjE=,size_16,color_FFFFFF,t_70" width="50%" height="50%">

4. **Sum & 合并注意力头**

    * 将每个v与score相乘，相加得到每个head的z

        <img src="https://img-blog.csdnimg.cn/2020022614353276.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2c1MzQ0NDE5MjE=,size_16,color_FFFFFF,t_70" width="50%" height="50%">

    * 合并注意力头：纵向连接

        <img src="https://img-blog.csdnimg.cn/20200226143642243.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2c1MzQ0NDE5MjE=,size_16,color_FFFFFF,t_70" width="50%" height="50%">

5. **投影**

    * 将连接得到的Z处理成FFNN能够处理的向量

    * 令注意力结果经过权重矩阵(768 x 768)，作为Masked Self-Attention的输出变量

        <img src="https://img-blog.csdnimg.cn/20200226144027601.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2c1MzQ0NDE5MjE=,size_16,color_FFFFFF,t_70" width="50%" height="50%">

        <img src="https://img-blog.csdnimg.cn/20200226144047904.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2c1MzQ0NDE5MjE=,size_16,color_FFFFFF,t_70" width="50%" height="50%">

#### 【Decoder】

* 原本Transformer有三层：self-attention + encoder-decoder attention + FFNN

* GPT：去掉encoder-decoder attention，创建测单字符的语言模型

* 注意：原本Transfomer在self-attention和FFNN后的Normalization层依旧被保留[Layer Norm](#**[完整结构]**)

    <img src="https://img-blog.csdnimg.cn/20200224212531722.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2c1MzQ0NDE5MjE=,size_16,color_FFFFFF,t_70" width="50%" height="50%">

#### 【FFNN】

1. **第一层**

    * 维度：embedding size x 4，提高模型的表征能力

        <img src="https://img-blog.csdnimg.cn/20200226144628656.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2c1MzQ0NDE5MjE=,size_16,color_FFFFFF,t_70" width="50%" height="50%">

2. 第二层

    * 投影回到模型尺寸（embedding size），利于后面与token embedding矩阵相乘

        <img src="https://img-blog.csdnimg.cn/2020022614472718.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2c1MzQ0NDE5MjE=,size_16,color_FFFFFF,t_70" width="50%" height="50%">

#### 【完整结构】

<img src="https://img-blog.csdnimg.cn/20200226144837725.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2c1MzQ0NDE5MjE=,size_16,color_FFFFFF,t_70" width="50%" height="50%">

### 训练方式

**【漫游】| ramble | 生成无条件样本**

* 用`<s>`作为开始标记，让GPT从开始标记直接开始生成单词

* 该token经过所有层，生成一个向量，维度是模型词汇表大小，每个词汇有一个得分

* 选择策略：选择概率最大或top-k中的任意

    > 只选择最优的推荐单词，可能会陷入重复循环

### Input Encoding

* **word embedding**

    * 每一行对应一个embedding，最小变体的维度为768

        > * 注意是token，未必是一个完整单词，可能是一个单词的一部分
        >
        > * GPT-2使用字节对(Byte pair)进行编码

    * vocab x embedding size

    <img src="https://img-blog.csdnimg.cn/2020022519480655.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2c1MzQ0NDE5MjE=,size_16,color_FFFFFF,t_70" style="zoom: 50%;" >

* **position encoding**

    * 每个位置有一个编码，共有1024个位置。一个有1024个token的序列，不足1024的，说明在1024位置之前先出现了`<end>`，则剩余用`<pad>`补足。

    * 1024 x embedding size

        <img src="https://img-blog.csdnimg.cn/20200225195505316.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2c1MzQ0NDE5MjE=,size_16,color_FFFFFF,t_70" style="zoom: 50%;" >

* **input**

    <img src="https://img-blog.csdnimg.cn/20200225195718305.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2c1MzQ0NDE5MjE=,size_16,color_FFFFFF,t_70" width="50%" height="50%">

### Output&迭代步骤

* self-attention经过FFNN的输出：即当前词对每个词的看重程度

* output：decoder#12的output 乘以 token embedding矩阵，计算出对每个词向量加权，求和

* 最终输出的是[batch_size,  max_token_len, vocab size]，对每个位置按一定策略解码。第n-1个token的向量用于预测第n个token的取值概率

    > 用第i个token的prediction_score用来预测第i+1个token。

    <img src="https://img-blog.csdnimg.cn/20200225203554477.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2c1MzQ0NDE5MjE=,size_16,color_FFFFFF,t_70" style="zoom: 43%;" >

    <img src="https://img-blog.csdnimg.cn/20200225203652621.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2c1MzQ0NDE5MjE=,size_16,color_FFFFFF,t_70" style="zoom:56%" >

* **选择策略**

    * 从中取出top-k（一般为40），分别计算40种情况下下一个位置的概率向量
    * 从中取出最大的一个，基于该词，计算下一个位置的可能词概率向量

* **迭代步骤**

    * 预：基于token embedding和position embedding得到attention的输入
    * 流动：经过self-attention，知道需要关注的词 =》FFNN
    * 得到输出（vocabsize x 1，每个词的出现概率）：将Decoder#12的FFNN输出乘以token embedding
    * 选择最大 或 top-40，进入下一轮迭代
    * 当生成1024个token，或产生end-of-sequence token.

## DialoGPT

### 简介

* 数据集

    * 2005~2017的Reddit评论链中提取的147M个对话
    * 存在问题：往往存在缩写、语法/词汇错误

    > <img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201123014258363.png" alt="image-20201123014258363" width="50%" height="50%"/>

* Dialog

    * 文本生成的子类，生成与提示句相关的文本
    * 属于一（输入）对多（输出）的问题

* DialoGPT

    * 在单轮对话上表现较好

    * 与GPT-2相比

        * 也是自回归语言模型 + 多层Transformer

            > 自回归语言模型：一次输出一个词，再将该输出添加到输入序列中，将新序列传入下一步作为输入

        * 数据集是Reddit评论链上的对话，可以在更细粒度的对话流上计算联合分布$P(target, source)$

### 模型结构

* 语料处理
    * 将一段对话处理为一个dialogue session，看作一段长文本。
    * $x_1, ... x_N$，有结束标记end-of-text token
        * Source Sentence：$S = x_1, ... x_m$
        * Target Sentence：$T = x_{m+1}, ... x_N$

* 语言模型

    $P(T|S) = \prod_{n=m+1}^N p(x_n|x_1, ..., x_{n-1})$

* 多轮问答

    $p(T_i|T_1, ..., T_{i-1})$

### 互信息最大化 | MMI

* MMI：maximum mutual informaton

* 反向模型

    * 根据答句预测问句

    * $P(Source|Target)$：采用Top-k生成一系列假设的source

        > Q：Hypothesis是指可能回答？

    * 惩罚安全回答：计算$p(source|hypothesis)$进行重排，安全回答可能对应多个source

        > 对于安全回答，比如“好的”，可能的source有“去爬山好不好”，“去看电影好不好”；
        >
        > 而“好的，我最喜欢看电影"的$p(source|hypothesis)$比较高

## MASK

* 神经网络的输入需要定长的张量，所以需要对文本进行裁剪或者填充，使其长度固定
* 通常用0填充，填充后，用mask向量(矩阵)$m$表示输入中每个元素的身份。有意义的为1，填充的为0.

### 【填充后的各项计算】

* **求平均**

    <img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201123081155890.png" alt="image-20201123081155890" width="50%" height="50%"/>

* **求最大值**

    <img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201123081218332.png" alt="image-20201123081218332" width="50%" height="50%"/>

* **softmax及其他**

    ![image-20201123081331036](https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201123081331036.png)

### 乱序语言模型 | XLNet

* **乱序**

    <img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201123081615572.png" alt="image-20201123081615572" width="50%" height="50%"/>

* **实现 | Mask掉Attention矩阵**

    * 蓝色部分，表示该词之前的词，保留其attention值

    ![image-20201123081702594](https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201123081702594.png)

* 为何可以

    * 输入向量本身已经有position embedding

    <img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201123081858309.png" alt="image-20201123081858309" width="50%" height="50%"/>

## UNILM

* UNLM：Unified Language Model Pre-Training for Natural Lnaguage Understanding and Generation

**【核心】**

* 将Transformer架构跟Seq2Seq结合

* 用单个BERT模型可以做Seq2Seq，无需区分encoder和decoder

* 思路：将Seq2Seq当成句子补全来做

    * 输入部分是双向语言模型，符合Seq2Seq的encoder
    * 输出部分是单向语言模型，符合Seq2Seq的decoder

    <img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201123082326507.png" alt="image-20201123082326507" width="50%" height="50%"/>


## Decoding Strategy

### Greedy Search

#### Greedy Search

* 每步选择当前最佳

#### Beam Search

* 广度优先基础上进行搜索空间优化，例如top-K
* 基于这K个可能，分别再计算每个可能的后续词 => $K^2$
* 实质：仍是greedy search，无法保证是全局最优

* 问题：答案容易重复

### Sampling

* 根据单词概率分布随机采样

#### 随机Sampling

* 步骤
    * 首先得到下一个单词在整个单词表上的概率分布是$p = (p_1, p_2, … p_{|V|})$
    * 根据概率分布随机采样，使生成的文字具备随机性
* 存在问题
    * 生成奇怪的话，用了罕见词
    * 生成的话容易不连贯，上下文矛盾

#### Temperature Sampling

* 用途：防止选择到罕见词，使罕见词的概率更低

* 在softmax中引入temperature t改变vocab的概率分布

    * 当t趋于无穷大，${u_t}/{t}$很相近，vocab相当于均匀分布
    * 当t趋于0，最大概率的词趋于无穷大，其概率接近1 => greedy search

    <img src="https://gitee.com/WIN0624/document/raw/markdown-picture/img/image-20201123141547583.png" alt="image-20201123141547583" width="50%" height="50%"/>

#### Top-k Sampling | K表示个数

* 缓解罕见词问题，每次只在Top-K可能性的单词（如概率最高的50个单词）中按照概率分布采样。选择后，重新softmax归一化后，再选择。
* 难点：K的选择
    * 当分布均匀时，一个较小的k容易丢掉很多优质候选词
    * 但如果k定的太大，这个方法又会退化回普通采样

#### Neucleus Sampling | 核采样

* 不取固定的k，而是固定候选集合的概率密度和在整个概率分布中的比例，即使说**选择的候选词集合的概率之和大于某个阈值** => 改进top-k遇到概率密度问题
* 步骤
    * 构造一个最小候选集V，使得$\sum_{x∈V}P(x) > p$
    * 重新归一化集合内词的概率，将集合外词的概率设为0

#### 惩罚重复

* 通过惩罚因子，降低出现过词的概率

## Bert两大任务

### MLM | Masked Language Model

* Mask一部分token，训练模型能够预测被去掉的token

### NSP | Next-Sentence Prediction

* 二分类任务：预测B句是不是A句的下一句

* [CLS]：将该符号对应输出作为整篇文本的语义表示，融合以下文本各个词的语义信息
* [SEP]：作为语句分隔符，则SEP前后的两个句子各自有一个文本向量来表征该句子

## Subword算法

* 传统空格分隔的缺陷
    * 容易OOV，无法处理罕见词
    * 没有学习到词根的关系

### BPE | Byte-Pair Encoding

* 原理

    最常见的一对连续字节数据被替换为该数据中不存在的字节。 后期使用时需要一个替换表来重建原始数据。

    > 比如我们想编码：
    >
    > aaabdaaabac
    >
    > 我们会发现这里的aa出现的词数最高（我们这里只看两个字符的频率），那么用这里没有的字符Z来替代aa：
    >
    > ZabdZabac
    >
    > Z=aa
    >
    > 此时，又发现ab出现的频率最高，那么同样的，Y来代替ab：
    >
    > ZYdZYac
    >
    > Y=ab
    >
    > Z=aa
    >
    > 同样的，ZY出现的频率大，我们用X来替代ZY：
    >
    > XdXac
    >
    > X=ZY
    >
    > Y=ab
    >
    > Z=aa
    >
    > 最后，连续两个字符的频率都为1了，也就结束了。就是这么简单。
    >
    > 解码的时候，就按照相反的顺序更新替换即可。

* 使用该算法的模型

    * GPT-2

    * RoBERTA

        

### WordPeice

### Unigram Language Model



